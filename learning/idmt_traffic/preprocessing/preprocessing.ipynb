{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import glob\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.signal\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDMTTrafficDataset(Dataset):\n",
    "    def __init__(self, X, y, zip_path, n_mels=None, target_sample_rate=22050):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.zfname = os.path.basename(zip_path).replace(\".zip\", \"\") + \"/audio/\"\n",
    "        self.archive = zipfile.ZipFile(zip_path)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "\n",
    "        self.classes = y.unique()\n",
    "        self.class_to_idx = {self.classes[i]: i for i in range(len(self.classes))}\n",
    "        \n",
    "        if n_mels == 16:            \n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=16,\n",
    "            )\n",
    "        elif n_mels == 32:\n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=32,\n",
    "            )\n",
    "        elif n_mels == 64:\n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=64,\n",
    "            )\n",
    "        else:\n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=128,\n",
    "            )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal, sample_rate = self.__load_signal__(idx)\n",
    "        signal = self.__mix_down_if_necessary__(signal)\n",
    "        signal = self.__resample_if_necessary__(signal, sample_rate)\n",
    "        mel_spec = self.mel_spec(signal)\n",
    "\n",
    "        label = self.__get_label__(idx)\n",
    "        \n",
    "        return mel_spec, label\n",
    "\n",
    "    def __load_signal__(self, idx):\n",
    "        audio_filename = self.zfname + self.X.iloc[idx]['file'] + \".wav\"\n",
    "        signal, sample_rate = torchaudio.load(io.BytesIO(self.archive.read(audio_filename)))\n",
    "        return signal, sample_rate\n",
    "    \n",
    "    def __mix_down_if_necessary__(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = signal.mean(axis=0)\n",
    "        return signal\n",
    "\n",
    "    def __resample_if_necessary__(self, signal, sample_rate):\n",
    "        if sample_rate != self.target_sample_rate:\n",
    "            signal = T.Resample(sample_rate, self.target_sample_rate)(signal)\n",
    "        return signal\n",
    "\n",
    "    def __get_label__(self, idx):\n",
    "        label = self.class_to_idx[self.y.iloc[idx]] \n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, zip_path):\n",
    "        self.archive = zipfile.ZipFile(zip_path)\n",
    "    \n",
    "        annotation_path = os.path.basename(zip_path).replace(\".zip\", \"\") + \"/annotation/\"\n",
    "        df_list = []\n",
    "\n",
    "        fn_txt_list = [\n",
    "            \"idmt_traffic_all.txt\",             # complete IDMT-Traffic dataset\n",
    "            \"eusipco_2021_train.txt\",     # training set of EUSIPCO 2021 paper\n",
    "            \"eusipco_2021_test.txt\"        # test set of EUSIPCO 2021 paper\n",
    "        ]\n",
    "\n",
    "        # import metadata\n",
    "        for fn_txt in fn_txt_list:\n",
    "            print(\"Metadata for {}: \".format(fn_txt))\n",
    "            df_list.append(self.import_idmt_traffic_dataset(annotation_path + fn_txt))\n",
    "\n",
    "        # Train Data\n",
    "        self.train_df = df_list[1]\n",
    "\n",
    "        # Test Data\n",
    "        self.test_df = df_list[2]\n",
    "\n",
    "    def train_val_test_split(self, val_size=0.2):\n",
    "        X = self.train_df.drop(columns=['date_time', 'location', 'sample_pos', 'microphone', 'channel', 'vehicle'])\n",
    "        y = self.train_df['vehicle']\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        X_val.reset_index(drop=True, inplace=True)\n",
    "        y_val.reset_index(drop=True, inplace=True)\n",
    "        print(f\"X_trian: {X_train.shape}\\ty_train: {y_train.shape}\")\n",
    "        print(f\"X_val: {X_val.shape}\\t\\ty_val: {y_val.shape}\")\n",
    "\n",
    "        X_test = self.test_df.drop(columns=['date_time', 'location', 'sample_pos', 'microphone', 'channel', 'vehicle'])\n",
    "        y_test = self.test_df['vehicle']\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        print(f\"X_test: {X_test.shape}\\ty_test: {y_test.shape}\")\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "    def import_idmt_traffic_dataset(self, fn_txt: str = \"idmt_traffic_all\") -> pd.DataFrame:\n",
    "        \"\"\" Import IDMT-Traffic dataset\n",
    "        Args:\n",
    "            fn_txt (str): Text file with all WAV files\n",
    "        Returns:\n",
    "            df_dataset (pd.Dataframe): File-wise metadata\n",
    "                Columns:\n",
    "                    'file': WAV filename,\n",
    "                    'is_background': True if recording contains background noise (no vehicle), False else\n",
    "                    'date_time': Recording time (YYYY-MM-DD-HH-mm)\n",
    "                    'location': Recording location\n",
    "                    'speed_kmh': Speed limit at recording site (km/h), UNK if unknown,\n",
    "                    'sample_pos': Sample position (centered) within the original audio recording,\n",
    "                    'daytime': M(orning) or (A)fternoon,\n",
    "                    'weather': (D)ry or (W)et road condition,\n",
    "                    'vehicle': (B)us, (C)ar, (M)otorcycle, or (T)ruck,\n",
    "                    'source_direction': Source direction of passing vehicle: from (L)eft or from (R)ight,\n",
    "                    'microphone': (SE)= (high-quality) sE8 microphones, (ME) = (low-quality) MEMS microphones (ICS-43434),\n",
    "                    'channel': Original stereo pair channel (12) or (34)\n",
    "        \"\"\"\n",
    "        # load file list\n",
    "        # df_files = pd.read_csv(fn_txt, names=('file',))\n",
    "        df_files = pd.read_csv(io.BytesIO(self.archive.read(fn_txt)), names=('file',))\n",
    "        fn_file_list = df_files['file'].to_list()\n",
    "\n",
    "        # load metadata from file names\n",
    "        df_dataset = []\n",
    "\n",
    "        for f, fn in enumerate(fn_file_list):\n",
    "            fn = fn.replace('.wav', '')\n",
    "            parts = fn.split('_')\n",
    "\n",
    "            # background noise files\n",
    "            if '-BG' in fn:\n",
    "                date_time, location, speed_kmh, sample_pos, mic, channel = parts\n",
    "                vehicle, source_direction, weather, daytime = 'None', 'None', 'None', 'None'\n",
    "                is_background = True\n",
    "\n",
    "            # files with vehicle passings\n",
    "            else:\n",
    "                date_time, location, speed_kmh, sample_pos, daytime, weather, vehicle_direction, mic, channel = parts\n",
    "                vehicle, source_direction = vehicle_direction\n",
    "                is_background = False\n",
    "\n",
    "            channel = channel.replace('-BG', '')\n",
    "            speed_kmh = speed_kmh.replace('unknownKmh', 'UNK')\n",
    "            speed_kmh = speed_kmh.replace('Kmh', '')\n",
    "\n",
    "            df_dataset.append({'file': fn,\n",
    "                            'is_background': is_background,\n",
    "                            'date_time': date_time,\n",
    "                            'location': location,\n",
    "                            'speed_kmh': speed_kmh,\n",
    "                            'sample_pos': sample_pos,\n",
    "                            'daytime': daytime,\n",
    "                            'weather': weather,\n",
    "                            'vehicle': vehicle,\n",
    "                            'source_direction': source_direction,\n",
    "                            'microphone': mic,\n",
    "                            'channel': channel})\n",
    "\n",
    "        df_dataset = pd.DataFrame(df_dataset, columns=('file', 'is_background', 'date_time', 'location', 'speed_kmh', 'sample_pos', 'daytime', 'weather', 'vehicle',\n",
    "                                                    'source_direction', 'microphone', 'channel'))\n",
    "\n",
    "        return df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for idmt_traffic_all.txt: \n",
      "Metadata for eusipco_2021_train.txt: \n",
      "Metadata for eusipco_2021_test.txt: \n",
      "X_trian: (4698, 6)\ty_train: (4698,)\n",
      "X_val: (1175, 6)\t\ty_val: (1175,)\n",
      "X_test: (2857, 6)\ty_test: (2857,)\n",
      "torch.Size([128, 87])\n",
      "0\n",
      "torch.Size([16, 87])\n",
      "1\n",
      "torch.Size([32, 87])\n",
      "2\n",
      "torch.Size([64, 87])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "preprocess = Preprocess(\"../dataset/IDMT_Traffic.zip\")\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess.train_val_test_split()\n",
    "\n",
    "idmt_dataset = IDMTTrafficDataset(X_train, y_train, \"../dataset/IDMT_Traffic.zip\", n_mels=128, target_sample_rate=22050)\n",
    "print(idmt_dataset[0][0].shape)\n",
    "print(idmt_dataset[0][1])\n",
    "\n",
    "idmt_dataset = IDMTTrafficDataset(X_train, y_train, \"../dataset/IDMT_Traffic.zip\", n_mels=16, target_sample_rate=22050)\n",
    "print(idmt_dataset[2][0].shape)\n",
    "print(idmt_dataset[2][1])\n",
    "\n",
    "idmt_dataset = IDMTTrafficDataset(X_train, y_train, \"../dataset/IDMT_Traffic.zip\", n_mels=32, target_sample_rate=22050)\n",
    "print(idmt_dataset[7][0].shape)\n",
    "print(idmt_dataset[7][1])\n",
    "\n",
    "idmt_dataset = IDMTTrafficDataset(X_train, y_train, \"../dataset/IDMT_Traffic.zip\", n_mels=64, target_sample_rate=22050)\n",
    "print(idmt_dataset[37][0].shape)\n",
    "print(idmt_dataset[37][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43926946470bb827d305256f979d20d06136168b26887207f85f0d5c88e9b0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
