{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 12:12:27.321216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 12:12:28.506713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 12:12:28.507087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 12:12:28.507108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal.windows import hann\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 4096                                                           # Window length in samples\n",
    "hop_perc = 39.9                                                                 # Hop length relative to window length ( chosen to obtain time_samples_num = 540)\n",
    "hop_len = int((hop_perc / 100.0) * window_len)     # Hop length in STFT calculation\n",
    "time_samples_num = 540                                              # Number of time samples where features are calculated\n",
    "mel_bands_num = 48                                                      # Number of mel bands\n",
    "signal_len = 20.0                                                               # signal length in seconds\n",
    "sample_rate = 44100\n",
    "\n",
    "LMS_adj_feat = 5                                                                          # Number of adjacent features to concatenate\n",
    "LMS_stride = 2                                                                              # LMS stride\n",
    "feat_num = (2 * LMS_adj_feat+1) * mel_bands_num    # Number of features\n",
    "f_min = 1000\n",
    "f_max = int(sample_rate / 2)\n",
    "tdt = 0.75                                                                                       # Time distance threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _load_signal(audio_filename):\n",
    "#     sample_rate, signal = wav.read(audio_filename)\n",
    "#     return signal, sample_rate\n",
    "\n",
    "# def _mix_if_necessary(signal):\n",
    "#     if len(signal.shape) == 2:\n",
    "#         signal = np.mean(signal, axis=1)\n",
    "#     return signal\n",
    "\n",
    "# def _cut_if_necessary(signal):\n",
    "#     if signal.size / sample_rate > signal_len:\n",
    "#         signal = signal[:int(sample_rate * signal_len)]\n",
    "#     return signal\n",
    "\n",
    "# def _pad_if_necessary(signal):\n",
    "#     if signal.size / sample_rate < signal_len:\n",
    "#         signal = np.pad(signal, int(signal_len * sample_rate - signal.size), mode='constant')\n",
    "#     return signal\n",
    "\n",
    "# def _resample_if_necessary(signal, sample_rate):\n",
    "#     if sample_rate != 44100:\n",
    "#         signal = librosa.resample(signal, sample_rate, 44100)\n",
    "#     return signal\n",
    "\n",
    "# def _get_num_of_frames(signal, frame_len, hop_len):\n",
    "#     return int((signal.size - frame_len) / hop_len) + 1\n",
    "\n",
    "# def _get_mel_transform_mtx(sample_rate, n_fft, n_mels, fmin, fmax):\n",
    "#     return librosa.filters.mel(sr=sample_rate, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax).T\n",
    "\n",
    "# def _get_log_mel_spectrogram(signal, window_len, hop_len, mel_transform_mtx):\n",
    "#     signal = np.pad(signal, int(window_len / 2), mode='constant')\n",
    "#     window = np.hamming(window_len)\n",
    "#     nb_frames = _get_num_of_frames(signal, window_len, hop_len)\n",
    "\n",
    "#     # Calculating log mel sepctrogram with FFT\n",
    "#     fft_en = np.zeros((nb_frames, int(1 + window_len / 2)))\n",
    "#     lms = np.zeros((nb_frames, mel_transform_mtx.shape[1]))\n",
    "\n",
    "#     for i in range(nb_frames):\n",
    "#         signal_window = signal[i * hop_len:i * hop_len + window_len] * window\n",
    "#         fft_aux = np.abs(fft(signal_window)[:1 + int(window_len / 2)])\n",
    "#         fft_aux[fft_aux == 0] = np.finfo(np.float32).eps\n",
    "#         fft_en[i, :] = fft_aux\n",
    "#         lms[i, :] = np.dot(fft_en[i, :]**2, mel_transform_mtx)\n",
    "    \n",
    "#     # Managing LMS outliers with extrapolating\n",
    "#     lms[lms == 0] = np.finfo(np.float32).eps\n",
    "#     lms = np.log(lms.T)\n",
    "\n",
    "#     inter_points = 7\n",
    "#     mean_diff = np.mean(np.mean(lms[:, 2:5], axis=1) - np.mean(lms[:, 0:2], axis=1))\n",
    "#     if mean_diff > 3:\n",
    "#         for k in range(lms.shape[0]):\n",
    "#             inter_val, coef, interc = _linear_interpolation(lms[k, 2:2+inter_points], 2, direction='L')\n",
    "#             lms[k, 0:2] = inter_val\n",
    "#     return lms\n",
    "\n",
    "# def _linear_interpolation(array, point_no, direction='L'):\n",
    "#     assert direction == 'L' or direction == 'R', \"Extrapolation direction not valid\"\n",
    "    \n",
    "#     arr_len = np.size(array)\n",
    "#     x = np.linspace(0,arr_len-1,arr_len).reshape(-1,1)\n",
    "#     lin_reg = LinearRegression().fit(x, array.reshape(-1,1))\n",
    "#     coef = np.float(lin_reg.coef_)\n",
    "#     interc = np.float(lin_reg.intercept_)\n",
    "#     if direction == 'L':\n",
    "#         x_extra = np.linspace(-point_no, -1, point_no)\n",
    "#     else:\n",
    "#         x_extra = np.linspace(arr_len, arr_len + point_no - 1, point_no)\n",
    "    \n",
    "#     y_extra = coef * x_extra + interc\n",
    "#     return y_extra, coef, interc\n",
    "\n",
    "# def _moving_average_filter(x, n):\n",
    "#     if n % 2 == 0:\n",
    "#         raise ValueError(\"Filter length is not odd\")\n",
    "\n",
    "#     aver = np.convolve(x, np.ones((n,)) / n, mode='same')\n",
    "#     n_half = int((n - 1) / 2)\n",
    "#     corr_length = np.array(range(n_half + 1, n)) / n\n",
    "#     aver[:n_half] = np.divide(aver[:n_half], corr_length)\n",
    "#     aver[-n_half:] = np.divide(aver[-n_half:], corr_length[::-1])\n",
    "\n",
    "#     return aver\n",
    "\n",
    "# def _filter_and_interpolate_lms(lms, points, step):\n",
    "#     refer_points = 10\n",
    "#     (lms_d0, _) = lms.shape[0], lms.shape[1]\n",
    "#     lms_copy = lms.copy()\n",
    "    \n",
    "#     lms_curr = None\n",
    "#     for k in range(points):\n",
    "#         lms_temp = lms_copy if k == 0 else lms_curr\n",
    "#         lms_curr = np.zeros_like(lms_copy)\n",
    "#         for j in range(lms_d0):\n",
    "#             arr_ext = _moving_average_filter(lms_temp[j,:refer_points], 3)       # Apply moving average filter\n",
    "#             add_left, coef, interc = _linear_interpolation(arr_ext, step, 'L')          # Use linear interpolation\n",
    "#             add_left = (add_left + lms_temp[j, :step]) / 2\n",
    "#             lms_curr[j, :step] = add_left\n",
    "#             lms_curr[j, step:] = lms_temp[j, :-step].copy()\n",
    "#             lms = np.concatenate((lms_curr, lms), axis=0)\n",
    "    \n",
    "#     lms_curr = None\n",
    "#     for k in range(points):\n",
    "#         lms_temp = lms_copy if k == 0 else lms_curr\n",
    "#         lms_curr = np.zeros_like(lms_copy)\n",
    "#         for j in range(lms_d0):\n",
    "#             arr_ext = _moving_average_filter(lms_temp[j,-refer_points:], 3)      # Apply moving average filter\n",
    "#             add_right, coef, interc = _linear_interpolation(arr_ext, step, 'R')      # User linear interpolation\n",
    "#             add_right = (add_right + lms_temp[j,-step:]) / 2\n",
    "#             lms_curr[j, :-step] = lms_temp[j, step:].copy()\n",
    "#             lms_curr[j, -step:] = add_right\n",
    "#         lms = np.concatenate((lms, lms_curr), axis=0)\n",
    "     \n",
    "#     lms_copy = lms_curr = lms_temp = None\n",
    "#     return lms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# item = 0\n",
    "# audio_filename = audio_files[item]\n",
    "\n",
    "# signal, sample_rate = _load_signal(audio_filename)\n",
    "# signal = _mix_if_necessary(signal)\n",
    "# signal = _cut_if_necessary(signal)\n",
    "# signal = _pad_if_necessary(signal)\n",
    "# signal = _resample_if_necessary(signal, sample_rate)\n",
    "\n",
    "# mel_transform_mtx = _get_mel_transform_mtx(sample_rate, window_len, mel_bands_num, f_min, f_max)\n",
    "# log_mel_spectrogram = _get_log_mel_spectrogram(signal, window_len, hop_len, mel_transform_mtx)\n",
    "# log_mel_spectrogram = _filter_and_interpolate_lms(log_mel_spectrogram, LMS_adj_feat, LMS_stride)\n",
    "# log_mel_spectrogram\n",
    "\n",
    "# feature = log_mel_spectrogram.T\n",
    "# feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_time_vec():\n",
    "#     signal = np.pad(signal, int(window_len / 2), mode='constant')\n",
    "#     nb_frames = _get_num_of_frames(signal, window_len, hop_len)\n",
    "#     time_vec = np.zeros((nb_frames,))\n",
    "#     for i in range(nb_frames):\n",
    "#         time_vec[i] = (i * hop_len) / sample_rate\n",
    "#     return time_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = 0\n",
    "# vc_filename = vc_files[item]\n",
    "\n",
    "# with open(vc_filename) as f:\n",
    "#     minima = f.readlines()\n",
    "\n",
    "# minima_positions = np.array([float(x.strip()) for x in minima])\n",
    "\n",
    "# vehicle_count = 0\n",
    "# if minima_positions[0] >= 0:\n",
    "#     vehicle_count = minima_positions.size\n",
    "# print(vehicle_count)\n",
    "\n",
    "# minima_no = minima_positions.size\n",
    "# labels_separate = np.empty((0, time_vec.size))\n",
    "# for k in range(minima_no):\n",
    "#     vehicle_label = tdt * np.ones_like(time_vec)\n",
    "#     if minima_positions[k] >= 0:\n",
    "#         abs_fun = np.abs(time_vec - minima_positions[k])\n",
    "#         vehicle_label = np.fmin(vehicle_label, abs_fun)\n",
    "#     labels_separate = np.append(labels_separate, vehicle_label.reshape(1, -1), axis=0)\n",
    "# labels = np.min(labels_separate, axis=0)\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    def __load_signal(self, audio_filename):\n",
    "        sample_rate, signal = wav.read(audio_filename)\n",
    "        if signal.dtype == np.int16:\n",
    "            signal = signal / 32768.0\n",
    "        return signal, sample_rate\n",
    "\n",
    "    def __mix_if_necessary(self, signal):\n",
    "        if len(signal.shape) == 2:\n",
    "            signal = np.mean(signal, axis=1)\n",
    "        return signal\n",
    "\n",
    "    def __cut_if_necessary(self, signal, sample_rate, signal_len):\n",
    "        if signal.size / sample_rate > signal_len:\n",
    "            signal = signal[:int(sample_rate * signal_len)]\n",
    "        return signal\n",
    "\n",
    "    def __pad_if_necessary(self, signal, sample_rate, signal_len):\n",
    "        if signal.size / sample_rate < signal_len:\n",
    "            signal = np.pad(signal, int((signal_len * sample_rate - signal.size) / 2), mode='constant')\n",
    "        return signal\n",
    "\n",
    "    def __resample_if_necessary(self, signal, sample_rate):\n",
    "        if sample_rate != 44100:\n",
    "            signal = librosa.resample(signal, sample_rate, 44100)\n",
    "        return signal\n",
    "\n",
    "    def __get_num_of_frames(self, signal, frame_len, hop_len):\n",
    "        return int((signal.size - frame_len) / hop_len) + 1\n",
    "\n",
    "    def __get_mel_transform_mtx(self, sample_rate, n_fft, n_mels, fmin, fmax):\n",
    "        return librosa.filters.mel(sr=sample_rate, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax).T\n",
    "\n",
    "    def __get_log_mel_spectrogram(self, signal, window_len, hop_len, mel_transform_mtx):\n",
    "        signal = np.pad(signal, int(window_len / 2), mode='constant')\n",
    "        window = np.hamming(window_len)\n",
    "        nb_frames = self.__get_num_of_frames(signal, window_len, hop_len)\n",
    "\n",
    "        # Calculating log mel sepctrogram with FFT\n",
    "        fft_en = np.zeros((nb_frames, int(1 + window_len / 2)))\n",
    "        lms = np.zeros((nb_frames, mel_transform_mtx.shape[1]))\n",
    "\n",
    "        for i in range(nb_frames):\n",
    "            signal_window = signal[i * hop_len:i * hop_len + window_len] * window\n",
    "            fft_aux = np.abs(fft(signal_window)[:1 + int(window_len / 2)])\n",
    "            fft_aux[fft_aux == 0] = np.finfo(np.float32).eps\n",
    "            fft_en[i, :] = fft_aux\n",
    "            lms[i, :] = np.dot(fft_en[i, :]**2, mel_transform_mtx)\n",
    "        \n",
    "        # Managing LMS outliers with extrapolating\n",
    "        lms[lms == 0] = np.finfo(np.float32).eps\n",
    "        lms = np.log(lms.T)\n",
    "\n",
    "        inter_points = 7\n",
    "        mean_diff = np.mean(np.mean(lms[:, 2:5], axis=1) - np.mean(lms[:, 0:2], axis=1))\n",
    "        if mean_diff > 3:\n",
    "            for k in range(lms.shape[0]):\n",
    "                inter_val, coef, interc = self.__linear_interpolation(lms[k, 2:2+inter_points], 2, direction='L')\n",
    "                lms[k, 0:2] = inter_val\n",
    "        return lms\n",
    "\n",
    "    def __linear_interpolation(self, array, point_no, direction='L'):\n",
    "        assert direction == 'L' or direction == 'R', \"Extrapolation direction not valid\"\n",
    "        \n",
    "        arr_len = np.size(array)\n",
    "        x = np.linspace(0,arr_len-1,arr_len).reshape(-1,1)\n",
    "        lin_reg = LinearRegression().fit(x, array.reshape(-1,1))\n",
    "        coef = np.float(lin_reg.coef_)\n",
    "        interc = np.float(lin_reg.intercept_)\n",
    "        if direction == 'L':\n",
    "            x_extra = np.linspace(-point_no, -1, point_no)\n",
    "        else:\n",
    "            x_extra = np.linspace(arr_len, arr_len + point_no - 1, point_no)\n",
    "        \n",
    "        y_extra = coef * x_extra + interc\n",
    "        return y_extra, coef, interc\n",
    "\n",
    "    def __moving_average_filter(self, x, n):\n",
    "        if n % 2 == 0:\n",
    "            raise ValueError(\"Filter length is not odd\")\n",
    "\n",
    "        aver = np.convolve(x, np.ones((n,)) / n, mode='same')\n",
    "        n_half = int((n - 1) / 2)\n",
    "        corr_length = np.array(range(n_half + 1, n)) / n\n",
    "        aver[:n_half] = np.divide(aver[:n_half], corr_length)\n",
    "        aver[-n_half:] = np.divide(aver[-n_half:], corr_length[::-1])\n",
    "\n",
    "        return aver\n",
    "\n",
    "    def __filter_and_interpolate_lms(self, lms, points, step):\n",
    "        refer_points = 10\n",
    "        (lms_d0, _) = lms.shape[0], lms.shape[1]\n",
    "        lms_copy = lms.copy()\n",
    "        \n",
    "        lms_curr = None\n",
    "        for k in range(points):\n",
    "            lms_temp = lms_copy if k == 0 else lms_curr\n",
    "            lms_curr = np.zeros_like(lms_copy)\n",
    "            for j in range(lms_d0):\n",
    "                arr_ext = self.__moving_average_filter(lms_temp[j,:refer_points], 3)       # Apply moving average filter\n",
    "                add_left, coef, interc =self.__linear_interpolation(arr_ext, step, 'L')          # Use linear interpolation\n",
    "                add_left = (add_left + lms_temp[j, :step]) / 2\n",
    "                lms_curr[j, :step] = add_left\n",
    "                lms_curr[j, step:] = lms_temp[j, :-step].copy()\n",
    "            lms = np.concatenate((lms_curr, lms), axis=0)\n",
    "        \n",
    "        lms_curr = None\n",
    "        for k in range(points):\n",
    "            lms_temp = lms_copy if k == 0 else lms_curr\n",
    "            lms_curr = np.zeros_like(lms_copy)\n",
    "            for j in range(lms_d0):\n",
    "                arr_ext = self.__moving_average_filter(lms_temp[j,-refer_points:], 3)      # Apply moving average filter\n",
    "                add_right, coef, interc = self.__linear_interpolation(arr_ext, step, 'R')      # User linear interpolation\n",
    "                add_right = (add_right + lms_temp[j,-step:]) / 2\n",
    "                lms_curr[j, :-step] = lms_temp[j, step:].copy()\n",
    "                lms_curr[j, -step:] = add_right\n",
    "            lms = np.concatenate((lms, lms_curr), axis=0)\n",
    "        \n",
    "        lms_copy = lms_curr = lms_temp = None\n",
    "        return lms\n",
    "    \n",
    "    def __load_audio(self, audio_filename, signal_len):\n",
    "        signal, sample_rate = self.__load_signal(audio_filename)\n",
    "        signal = self.__mix_if_necessary(signal)\n",
    "        signal = self.__cut_if_necessary(signal, sample_rate, signal_len)\n",
    "        signal = self.__pad_if_necessary(signal, sample_rate, signal_len)\n",
    "        signal = self.__resample_if_necessary(signal, sample_rate)\n",
    "        return signal\n",
    "    \n",
    "    def __get_time_vec(self, signal, window_len, hop_len, sample_rate):\n",
    "        signal = np.pad(signal, int(window_len / 2), mode='constant')\n",
    "        nb_frames = self.__get_num_of_frames(signal, window_len, hop_len)\n",
    "        time_vec = np.zeros((nb_frames,))\n",
    "        for i in range(nb_frames):\n",
    "            time_vec[i] = (i * hop_len) / sample_rate\n",
    "        return time_vec\n",
    "\n",
    "    def __get_feature(self, signal, sample_rate, window_len, hop_len, mel_bands_num, f_min, f_max, adj_feat, stride):\n",
    "        mel_transform_mtx = self.__get_mel_transform_mtx(sample_rate, window_len, mel_bands_num, f_min, f_max)\n",
    "        log_mel_spectrogram = self.__get_log_mel_spectrogram(signal, window_len, hop_len, mel_transform_mtx)\n",
    "        log_mel_spectrogram = self.__filter_and_interpolate_lms(log_mel_spectrogram, adj_feat, stride)\n",
    "        feature = log_mel_spectrogram.T\n",
    "        return feature\n",
    "\n",
    "    def __get_vehicle_count(self, vc_filename):\n",
    "        with open(vc_filename) as f:\n",
    "            minima = f.readlines()\n",
    "        minima_positions = np.array([float(x.strip()) for x in minima])\n",
    "        vehicle_count = 0\n",
    "        if minima_positions[0] >= 0:\n",
    "            vehicle_count = minima_positions.size\n",
    "        return vehicle_count\n",
    "    \n",
    "    def __get_label(self, vc_filename, time_vec, tdt):\n",
    "        with open(vc_filename) as f:\n",
    "            minima = f.readlines()\n",
    "\n",
    "        minima_positions = np.array([float(x.strip()) for x in minima])\n",
    "        minima_no = minima_positions.size\n",
    "        labels_separate = np.empty((0, time_vec.size))\n",
    "        for k in range(minima_no):\n",
    "            vehicle_label = tdt * np.ones_like(time_vec)\n",
    "            if minima_positions[k] >= 0:\n",
    "                abs_fun = np.abs(time_vec - minima_positions[k])\n",
    "                vehicle_label = np.fmin(vehicle_label, abs_fun)\n",
    "            labels_separate = np.append(labels_separate, vehicle_label.reshape(1, -1), axis=0)\n",
    "        labels = np.min(labels_separate, axis=0)\n",
    "        return labels\n",
    "    \n",
    "    def create(self, audio_folder, signal_len, time_samples_num, feat_num, adj_feat, stride, tdt, out_dataset_name=\"dataset.h5\"):\n",
    "        audio_files = sorted(glob.glob(audio_folder + \"*.wav\"))\n",
    "        vc_files = sorted(glob.glob(audio_folder + \"*.txt\"))\n",
    "\n",
    "        files_num = len(audio_files)\n",
    "        features = np.zeros((files_num, time_samples_num, feat_num))\n",
    "        labels = np.zeros((files_num, time_samples_num))\n",
    "        vehicle_counts = np.zeros((files_num,))\n",
    "\n",
    "        for file_index in tqdm(range(len(audio_files))):\n",
    "            audio_filename = audio_files[file_index]\n",
    "\n",
    "            signal = self.__load_audio(audio_filename, signal_len)\n",
    "            time_vec = self.__get_time_vec(signal, window_len, hop_len, sample_rate)\n",
    "            features[file_index, :, :]= self.__get_feature(signal, sample_rate, window_len, hop_len, mel_bands_num, f_min, f_max, adj_feat, stride)\n",
    "\n",
    "            vc_filename = vc_files[file_index]\n",
    "            labels[file_index, :] = self.__get_label(vc_filename, time_vec, tdt)\n",
    "            vehicle_counts[file_index] = self.__get_vehicle_count(vc_filename)\n",
    "\n",
    "        hf = h5py.File(out_dataset_name, 'w')\n",
    "        hf.create_dataset('features', data=features, compression=\"gzip\")\n",
    "        hf.create_dataset('labels', data=labels, compression=\"gzip\")\n",
    "        hf.create_dataset('vehicle_counts', data=vehicle_counts, compression=\"gzip\")\n",
    "        hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [12:07<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "audio_folder = \"../VC-PRG-1_5/\"\n",
    "audio_files = sorted(glob.glob(audio_folder + \"*.wav\"))\n",
    "vc_files = sorted(glob.glob(audio_folder + \"*.txt\"))\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "train_ds = CreateDataset()\n",
    "train_ds.create(audio_folder, signal_len, time_samples_num, feat_num, LMS_adj_feat, LMS_stride, tdt, \"datasets/train_dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [05:42<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "audio_folder = \"../VC-PRG-6/\"\n",
    "audio_files = sorted(glob.glob(audio_folder + \"*.wav\"))\n",
    "vc_files = sorted(glob.glob(audio_folder + \"*.txt\"))\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "test_ds = CreateDataset()\n",
    "test_ds.create(audio_folder, signal_len, time_samples_num, feat_num, LMS_adj_feat, LMS_stride, tdt, \"datasets/test_dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c71ccffe01fdfb295996a0f65a7af17abd82c3a990a1d3150e0ac70e6643c9b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
