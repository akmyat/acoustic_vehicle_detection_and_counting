{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import glob\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VcdDataset(Dataset):\n",
    "    def __init__(self, X, y, zip_path, n_mels=None, sample_length=20, target_sample_rate=22050, classes=10):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.sample_length = sample_length\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = int(self.sample_length * self.target_sample_rate)\n",
    "        \n",
    "        self.zfname = os.path.basename(zip_path).replace(\".zip\", \"\") + \"/\"\n",
    "        self.archive = zipfile.ZipFile(zip_path)\n",
    "\n",
    "        self.classes = [i for i in range(classes)]\n",
    "        self.class_to_idx = {self.classes[i]: i for i in range(len(self.classes))}\n",
    "\n",
    "        if n_mels == 16:\n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "        elif n_mels == 32:\n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "        elif n_mels == 64:\n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "        else:\n",
    "            self.mel_spec = T.MelSpectrogram(\n",
    "                sample_rate=22050,\n",
    "                n_fft=2048,\n",
    "                win_length=1024,\n",
    "                hop_length=512,\n",
    "                n_mels=128,\n",
    "            )                        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        signal, sample_rate = self.__load_signal__(idx)\n",
    "        return signal, sample_rate        \n",
    "\n",
    "    def __load_signal__(self, idx):\n",
    "        audio_filename = self.zfname + self.X.iloc[idx]['file']\n",
    "        signal, sample_rate = torchaudio.load(io.BytesIO(self.archive.read(audio_filename)))\n",
    "        signal = self.__mix_down_if_necessary__(signal)\n",
    "        signal = self.__resample_if_necessary__(signal, sample_rate)\n",
    "        signal = self.__cut_if_necessary__(signal)\n",
    "        signal = self.__right_pad_if_necessary__(signal)\n",
    "        mel_spec = self.mel_spec(signal)\n",
    "        log_mel_spec = self.__convert_to_db_scale__(mel_spec)\n",
    "        img = self.__convert_to_image__(log_mel_spec)\n",
    "\n",
    "        label = self.__get_label__(idx)\n",
    "        return img, label\n",
    "\n",
    "    def __mix_down_if_necessary__(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = signal.mean(axis=0)\n",
    "        return signal\n",
    "\n",
    "    def __resample_if_necessary__(self, signal, sample_rate):\n",
    "        if sample_rate != self.target_sample_rate:\n",
    "            signal = T.Resample(sample_rate, self.target_sample_rate)(signal)\n",
    "        return signal\n",
    "\n",
    "    def __cut_if_necessary__(self, signal):\n",
    "        if signal.size(0) > self.num_samples:\n",
    "            signal = signal[:self.num_samples]\n",
    "        return signal\n",
    "    \n",
    "    def __right_pad_if_necessary__(self, signal):\n",
    "        if signal.size(0) < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - signal.size(0)\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "        \n",
    "    def __convert_to_db_scale__(self, mel_spec):\n",
    "        log_mel_spec = F.amplitude_to_DB(mel_spec, 10, 1e-10, np.log10(max(mel_spec.max(), 1e-10)))\n",
    "        return log_mel_spec\n",
    "    \n",
    "    def __convert_to_image__(self, log_mel_spec):\n",
    "        eps  = 1e-6\n",
    "        mean = log_mel_spec.mean()\n",
    "        std = log_mel_spec.std()\n",
    "        log_mel_spec_norm = (log_mel_spec - mean) / (std + eps)\n",
    "        spec_min, spec_max = log_mel_spec_norm.min(), log_mel_spec_norm.max()\n",
    "        img = 255 * (log_mel_spec_norm - spec_min) / (spec_max - spec_min)\n",
    "        img = ToPILImage()(img).convert('RGB')\n",
    "        img_tensor = ToTensor()(img)\n",
    "        normalize_img = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img_tensor)\n",
    "        return normalize_img\n",
    "\n",
    "    def __get_label__(self, idx):\n",
    "        label = self.class_to_idx[self.y.iloc[idx]] \n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, train_zip_path, test_zip_path):\n",
    "        self. X_train, self.y_train = self.load_data(train_zip_path)\n",
    "        self.X_test, self.y_test = self.load_data(test_zip_path)\n",
    "        \n",
    "        self.train_df = pd.DataFrame(self.X_train, columns=['file'])\n",
    "        self.train_df['vehicle_count'] = self.y_train\n",
    "\n",
    "        self.test_df = pd.DataFrame(self.X_test, columns=['file'])\n",
    "        self.test_df['vehicle_count'] = self.y_test\n",
    "\n",
    "    def load_data(self, zip_path):\n",
    "        zfname = os.path.basename(zip_path).replace('.zip', '') + \"/\"\n",
    "        archive = zipfile.ZipFile(zip_path, 'r')\n",
    "        X = [os.path.basename(file) for file in archive.namelist() if '.wav' in file]\n",
    "\n",
    "        y = []\n",
    "        vc_files = [os.path.basename(file) for file in archive.namelist() if '.txt' in file]\n",
    "        for file in vc_files:\n",
    "            vehicle_count = self.get_vehicle_count(archive, zfname + file)\n",
    "            y.append(vehicle_count)\n",
    "        return X, y\n",
    "    \n",
    "    def get_vehicle_count(self, zipfile, filename):\n",
    "        with zipfile.open(filename) as f:\n",
    "            minima = f.readlines()\n",
    "        minima_positions = np.array([float(x.strip()) for x in minima])\n",
    "        vehicle_count = 0\n",
    "        if minima_positions[0] >= 0:\n",
    "            vehicle_count = minima_positions.size\n",
    "        return vehicle_count\n",
    "\n",
    "    def train_val_test_split(self, val_size=0.2):\n",
    "        X = self.train_df.drop(columns=['vehicle_count'])\n",
    "        y = self.train_df['vehicle_count']\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_size, random_state=42)\n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        X_val.reset_index(drop=True, inplace=True)\n",
    "        y_val.reset_index(drop=True, inplace=True)\n",
    "        print(f\"X_trian: {X_train.shape}\\ty_train: {y_train.shape}\")\n",
    "        print(f\"X_val: {X_val.shape}\\t\\ty_val: {y_val.shape}\")\n",
    "\n",
    "        X_test = self.test_df.drop(columns=['vehicle_count'])\n",
    "        y_test = self.test_df['vehicle_count']\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        print(f\"X_test: {X_test.shape}\\ty_test: {y_test.shape}\")\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test        \n",
    "\n",
    "    def train_test_split(self):\n",
    "        X_train = self.train_df.drop(columns=['vehicle_count'])\n",
    "        y_train = self.train_df['vehicle_count']\n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        print(f\"X_trian: {X_train.shape}\\ty_train: {y_train.shape}\")\n",
    "\n",
    "        X_test = self.test_df.drop(columns=['vehicle_count'])\n",
    "        y_test = self.test_df['vehicle_count']\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        print(f\"X_test: {X_test.shape}\\ty_test: {y_test.shape}\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trian: (200, 1)\ty_train: (200,)\n",
      "X_val: (50, 1)\t\ty_val: (50,)\n",
      "X_test: (172, 1)\ty_test: (172,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wav: wave header missing extended part of fmt chunk\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test \u001b[39m=\u001b[39m pmodule\u001b[39m.\u001b[39mtrain_val_test_split()\n\u001b[1;32m      6\u001b[0m train_dataset \u001b[39m=\u001b[39m VcdDataset(X_train, y_train, train_zip_path)\n\u001b[0;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(train_dataset[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(train_dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m])\n\u001b[1;32m     10\u001b[0m val_dataset \u001b[39m=\u001b[39m VcdDataset(X_val, y_val, train_zip_path)\n",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mVcdDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 52\u001b[0m     signal, sample_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load_signal__(idx)\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m signal, sample_rate\n",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m, in \u001b[0;36mVcdDataset.__load_signal__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     58\u001b[0m signal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__mix_down_if_necessary__(signal)\n\u001b[1;32m     59\u001b[0m signal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__resample_if_necessary__(signal, sample_rate)\n\u001b[0;32m---> 60\u001b[0m signal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__cut_if_necessary__(signal)\n\u001b[1;32m     61\u001b[0m signal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__right_pad_if_necessary__(signal)\n\u001b[1;32m     62\u001b[0m mel_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmel_spec(signal)\n",
      "Cell \u001b[0;32mIn[2], line 80\u001b[0m, in \u001b[0;36mVcdDataset.__cut_if_necessary__\u001b[0;34m(self, signal)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__cut_if_necessary__\u001b[39m(\u001b[39mself\u001b[39m, signal):\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mif\u001b[39;00m signal\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples:\n\u001b[1;32m     81\u001b[0m         signal \u001b[39m=\u001b[39m signal[:, :\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples]\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m signal\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "train_zip_path = \"../dataset/VC-PRG-1_5.zip\"\n",
    "test_zip_path = \"../dataset/VC-PRG-6.zip\"\n",
    "pmodule = Preprocess(train_zip_path, test_zip_path)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = pmodule.train_val_test_split()\n",
    "\n",
    "train_dataset = VcdDataset(X_train, y_train, train_zip_path)\n",
    "print(train_dataset[0][0].shape)\n",
    "print(train_dataset[0][1])\n",
    "\n",
    "val_dataset = VcdDataset(X_val, y_val, train_zip_path)\n",
    "print(val_dataset[0][0].shape)\n",
    "print(val_dataset[0][1])\n",
    "\n",
    "test_dataset = VcdDataset(X_test, y_test, test_zip_path)\n",
    "print(test_dataset[0][0].shape)\n",
    "print(test_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trian: (250, 1)\ty_train: (250,)\n",
      "X_test: (172, 1)\ty_test: (172,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wav: wave header missing extended part of fmt chunk\n",
      "wav: wave header missing extended part of fmt chunk\n",
      "wav: wave header missing extended part of fmt chunk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 862])\n",
      "3\n",
      "torch.Size([3, 128, 862])\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wav: wave header missing extended part of fmt chunk\n"
     ]
    }
   ],
   "source": [
    "train_zip_path = \"../dataset/VC-PRG-1_5.zip\"\n",
    "test_zip_path = \"../dataset/VC-PRG-6.zip\"\n",
    "pmodule = Preprocess(train_zip_path, test_zip_path)\n",
    "X_train, X_test, y_train, y_test = pmodule.train_test_split()\n",
    "\n",
    "train_dataset = VcdDataset(X_train, y_train, train_zip_path)\n",
    "print(train_dataset[0][0].shape)\n",
    "print(train_dataset[0][1])\n",
    "\n",
    "test_dataset = VcdDataset(X_test, y_test, test_zip_path)\n",
    "print(test_dataset[0][0].shape)\n",
    "print(test_dataset[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43926946470bb827d305256f979d20d06136168b26887207f85f0d5c88e9b0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
