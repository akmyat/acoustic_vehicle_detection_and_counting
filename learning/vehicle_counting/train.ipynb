{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 4096   # Window length in samples\n",
    "hop_perc = 40 # Hop length relative to window size (percents)\n",
    "hop_len = int((hop_perc / 100.0) * window_len) # Hop length in the STFT calculation\n",
    "mel_bands_num = 64 # Number of Mel-bands to calculate Mel-band energy feature\n",
    "signal_len = 20.0 # Signal length in seconds\n",
    "\n",
    "adj_feat_num = 10 # Number of adjacent features to concatenate (only for 1-D features)\n",
    "feat_num = mel_bands_num + 3 * (2 * adj_feat_num + 1) # Number of features (mel_bands_num + 1-D time features)\n",
    "time_samples_num = 539 # Number of time samples where features are calcuated\n",
    "time_dist_threshold = 0.75 # Time distance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature2index(feat_list, feat_inds):\n",
    "    inds = np.array([])\n",
    "    for feat in feat_inds:\n",
    "        if feat in feat_list:\n",
    "            inds = np.append(inds, feat_inds[feat])\n",
    "    inds = np.sort(inds).astype('int')\n",
    "    return inds\n",
    "\n",
    "def feats_string(feats, feat_inds):\n",
    "    fs = []\n",
    "    for feat in feat_inds:\n",
    "        if feat in feats:\n",
    "            fs.append(feat)\n",
    "    fs = \"#\".join(fs)\n",
    "    return fs\n",
    "\n",
    "def compare_prediction_and_gt(y_pred, y_gt, dec_thresh):\n",
    "    cars_correct = false_pos = false_neg = 0\n",
    "\n",
    "    for k in range(y_pred.shape[0]):\n",
    "        gt_row = y_gt[k, :].flatten()\n",
    "        peaks_gt = find_peaks(np.max(gt_row) - gt_row)[0]\n",
    "        gt_intervals = np.zeros((peaks_gt.size, 2))\n",
    "        for j in range(peaks_gt.size):\n",
    "            aux = peaks_gt[j]\n",
    "            while aux > 0 and gt_row[aux] < gt_row[aux -1]:\n",
    "                aux -= 1\n",
    "            gt_intervals[j, 0] = aux\n",
    "            aux = peaks_gt[j]\n",
    "            while aux < gt_row.size -1 and gt_row[aux] < gt_row[aux + 1]:\n",
    "                aux += 1\n",
    "            gt_intervals[j, 1] = aux\n",
    "    \n",
    "    pred_row = y_pred[k, :].flatten()\n",
    "    pred_row_inv = np.max(pred_row) - pred_row\n",
    "    peaks_pos = find_peaks(pred_row_inv, prominence=0.05)[0]\n",
    "    pred_peak_pos = peaks_pos[np.argwhere(pred_row[peaks_pos] < dec_thresh)].flatten()\n",
    "    for j in range(pred_peak_pos.size):\n",
    "        within = np.logcial_and(gt_intervals[:, 0] < pred_peak_pos[j], gt_intervals[:, 1] > pred_peak_pos[j])\n",
    "        ind_within = np.argwhere(within).flatten()\n",
    "        if ind_within.size > 0:\n",
    "            cars_correct += 1\n",
    "            gt_itervals = np.delete(gt_intervals, ind_within[0], axis=0)\n",
    "        else:\n",
    "            flase_pos += 1\n",
    "    false_neg += gt_intervals.shape[0]\n",
    "    return cars_correct, false_pos, false_neg\n",
    "\n",
    "def detection_postprocessing(y_pred):\n",
    "    y_pred_proc = y_pred.copy()\n",
    "    for k in range(y_pred_proc.shape[0]):\n",
    "        row = y_pred_proc[k, :].flatten()\n",
    "        row = running_mean(row, 7)\n",
    "        row = running_mean(row, 5)\n",
    "        row = running_mean(row, 3)\n",
    "        y_pred_proc[k, :] = row\n",
    "\n",
    "    return y_pred_proc\n",
    "\n",
    "def car_detection(y_pred, y_gt, decision_thresh):\n",
    "    assert y_pred.shape == y_gt.shape, \"Predicted and ground truth arrays are not the same dimensions\"\n",
    "    \n",
    "    y_pred_proc = detection_postprocessing(y_pred)\n",
    "    correct, false_pos, false_neg = compare_prediction_and_gt(y_pred_proc, y_gt, decision_thresh)\n",
    "\n",
    "    return correct, false_pos, false_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "epsilon = 0.05\n",
    "feat_inds = {\n",
    "    \"ste\" : np.arange(0 * (2 * adj_feat_num + 1), 1 * (2 * adj_feat_num + 1)),\n",
    "    \"trf\" : np.arange(1 * (2 * adj_feat_num + 1), 2 * (2 * adj_feat_num + 1)),\n",
    "    \"hfp\" : np.arange(2 * (2 * adj_feat_num + 1), 3 * (2 * adj_feat_num + 1)),\n",
    "    \"lms\" : np.arange(3 * (2 * adj_feat_num + 1), feat_num)\n",
    "}\n",
    "curr_feats = [\"ste\", \"trf\", \"hfp\", \"lms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (250, 539, 127)\n",
      "Y shape:  (250, 539)\n",
      "VC shape:  (250,)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'datasets/dataset_cross-validation.h5'\n",
    "hf = h5py.File(dataset, 'r')\n",
    "x = np.array(hf['features'], dtype=np.float64)\n",
    "y = np.array(hf['labels'], dtype=np.float64)\n",
    "vc = np.array(hf['vehicle_count'])\n",
    "hf.close()\n",
    "\n",
    "print(\"X shape: \", x.shape)\n",
    "print(\"Y shape: \", y.shape)\n",
    "print(\"VC shape: \", vc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_keep = feature2index(curr_feats, feat_inds)\n",
    "feat_string = feats_string(curr_feats, feat_inds)\n",
    "x = x[:, :, inds_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_perm = np.random.RandomState().permutation(x.shape[0])\n",
    "x = x[rand_perm, :, :]\n",
    "y = y[rand_perm, :]\n",
    "vc = vc[rand_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_perc = np.arange(0, 101, 1)\n",
    "thresh_len = thresh_perc.size\n",
    "correct = np.zeros((thresh_len,))\n",
    "false_pos = np.zeros((thresh_len,))\n",
    "false_neg = np.zeros((thresh_len,))\n",
    "\n",
    "RVCE = np.zeros((thresh_len,))\n",
    "y_pred_all = np.zeros_like(y)\n",
    "y_test_all = np.zeros_like(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "kf.get_n_splits(x)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train = x_train.reshape(x_train.shape[0] * x_train.shape[1], x_train.shape[2])\n",
    "    y_train = y_train.reshape(-1, )\n",
    "    x_test = x_test.reshape(x_test.shape[0] * x_test.shape[1], x_test.shape[2])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    regressor = SVR(gamma='scale', C=C, epsilon=epsilon)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    y_pred = y_pred.reshape(-1, time_samples_num)\n",
    "    y_pred_all[test_index, :] = y_pred.copy()\n",
    "    y_test_all[test_index, :] = y_test.copy()\n",
    "\n",
    "    veh_count = np.sum(vc[test_index])\n",
    "    for j in range(thresh_len):\n",
    "        (corr, fp, fn) = car_detection(y_pred, y_test, (thresh_perc[j] / 100) * time_dist_threshold)\n",
    "        correct[j] += corr / veh_count\n",
    "        false_pos[j] += fp / veh_count\n",
    "        false_neg[j] += fn / veh_count\n",
    "        RVCE[j] += abs(veh_count - (corr + fp)) / veh_count\n",
    "    \n",
    "    print(\"Fold done\")\n",
    "\n",
    "correct = (correct / folds) * 100\n",
    "false_pos = (false_pos / folds) * 100\n",
    "false_neg = (false_neg /folds) * 100\n",
    "RVCE =(RVCE / folds) * 100\n",
    "\n",
    "SVR_file = f\"SVR_feat#{feat_string}_Exp1.h5\"\n",
    "hf = h5py.File('SVR/' + SVR_file, 'w')\n",
    "hf.create_dataset('test_pred', data=y_pred_all, compression=\"gzip\")\n",
    "hf.create_dataset('test_gt', data=y_test_all, compression=\"gzip\")\n",
    "hf.close()\n",
    "\n",
    "probs_file = f\"Probs_feat#{feat_string}_Exp1.h5\"\n",
    "hf = h5py.File('Probs/' + probs_file, 'w')\n",
    "hf.create_dataset('correct', data=correct, compression=\"gzip\")\n",
    "hf.create_dataset('false_pos', data=false_pos, compression=\"gzip\")\n",
    "hf.create_dataset('false_neg', data=false_neg, compression=\"gzip\")\n",
    "hf.close()\n",
    "\n",
    "RVCE_file = f\"RVCE_feat#{feat_string}_Exp1.h5\"\n",
    "hf = h5py.File('RVCE/' + RVCE_file, 'w')\n",
    "hf.create_dataset('RVCE', data=RVCE, compression=\"gzip\")\n",
    "hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43926946470bb827d305256f979d20d06136168b26887207f85f0d5c88e9b0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
